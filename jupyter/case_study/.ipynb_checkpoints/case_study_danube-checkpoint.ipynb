{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:10:25.461717Z",
     "start_time": "2020-02-19T16:10:23.596943Z"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:12:02.299189Z",
     "start_time": "2020-02-19T16:12:02.252619Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/flood_prediction/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In xarray version 0.15 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  \n",
      "/opt/miniconda3/envs/flood_prediction/lib/python3.7/site-packages/xarray/backends/api.py:933: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (latitude: 83, longitude: 221, time: 7610)\n",
       "Coordinates:\n",
       "  * latitude   (latitude) float64 50.45 50.35 50.25 50.15 ... 42.45 42.35 42.25\n",
       "  * longitude  (longitude) float64 8.05 8.15 8.25 8.35 ... 29.85 29.95 30.05\n",
       "  * time       (time) datetime64[ns] 1999-01-01 1999-01-02 ... 2019-11-01\n",
       "Data variables:\n",
       "    dis24      (time, latitude, longitude) float32 dask.array&lt;chunksize=(5114, 83, 221), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    CDI:                       Climate Data Interface version 1.9.6 (http://m...\n",
       "    Conventions:               CF-1.6\n",
       "    history:                   Thu Oct 10 12:28:51 2019: cdo -seldate,1999-01...\n",
       "    cdo_openmp_thread_number:  8\n",
       "    NCO:                       netCDF Operators version 4.7.8 (Homepage = htt...\n",
       "    CDO:                       Climate Data Operators version 1.9.6 (http://m...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 83, longitude: 221, time: 7610)\n",
       "Coordinates:\n",
       "  * latitude   (latitude) float64 50.45 50.35 50.25 50.15 ... 42.45 42.35 42.25\n",
       "  * longitude  (longitude) float64 8.05 8.15 8.25 8.35 ... 29.85 29.95 30.05\n",
       "  * time       (time) datetime64[ns] 1999-01-01 1999-01-02 ... 2019-11-01\n",
       "Data variables:\n",
       "    dis24      (time, latitude, longitude) float32 dask.array<chunksize=(5114, 83, 221), meta=np.ndarray>\n",
       "Attributes:\n",
       "    CDI:                       Climate Data Interface version 1.9.6 (http://m...\n",
       "    Conventions:               CF-1.6\n",
       "    history:                   Thu Oct 10 12:28:51 2019: cdo -seldate,1999-01...\n",
       "    cdo_openmp_thread_number:  8\n",
       "    NCO:                       netCDF Operators version 4.7.8 (Homepage = htt...\n",
       "    CDO:                       Climate Data Operators version 1.9.6 (http://m..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Case study needs fixing \n",
    "glofas = xr.open_mfdataset('/Volumes/portableHardDisk/data/glofas_region/Danube/glofas_masked_danube_*.nc')\n",
    "\n",
    "glofas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:12:10.211296Z",
     "start_time": "2020-02-19T16:12:09.350199Z"
    }
   },
   "outputs": [],
   "source": [
    "from functions.floodmodel_utils import get_basin_mask, get_river_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:41:37.967221Z",
     "start_time": "2020-02-19T16:41:37.926145Z"
    }
   },
   "outputs": [],
   "source": [
    "#eps = xr.open_mfdataset('/tmp/flood_prediction/pipeline/glofas2.1_2018_areagrid_for_StevenGong_in_Europe_*.nc', combine=\"nested\", concat_dim='time')\n",
    "eps = xr.open_dataset('/Volumes/portableHardDisk/data/EPS/europeEPS201306/glofas2.1_2018_areagrid_for_StevenGong_in_Europe_2013060400.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5 = xr.open_mfdataset(\"/Volumes/portableHardDisk/data/Europe/reanalysis-era5-single-levels_convective_precipitation,land_sea_mask,large_scale_precipitation,runoff,slope_of_sub_gridscale_orography,soil_type,total_column_water_vapour,volumetric_soil_water_layer_1,volumetric_soil_water_layer_2_*.nc\", combine=\"by_coords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:41:38.115742Z",
     "start_time": "2020-02-19T16:41:38.066489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (ensemble: 11, latitude: 450, longitude: 750, time: 31)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 2013-06-04 2013-06-05 ... 2013-07-04\n",
       "  * longitude  (longitude) float32 -24.95 -24.85 -24.75 ... 49.75 49.85 49.95\n",
       "  * latitude   (latitude) float32 74.95 74.85 74.75 74.65 ... 30.25 30.15 30.05\n",
       "  * ensemble   (ensemble) float64 0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0\n",
       "Data variables:\n",
       "    ups        (latitude, longitude) float32 ...\n",
       "    ldd        (latitude, longitude) float32 ...\n",
       "    rl2        (latitude, longitude) float32 ...\n",
       "    rl5        (latitude, longitude) float32 ...\n",
       "    rl20       (latitude, longitude) float32 ...\n",
       "    dis        (time, ensemble, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    CDI:          Climate Data Interface version 1.9.6 (http://mpimet.mpg.de/...\n",
       "    history:      Fri Feb 14 21:34:47 2020: cdo -f nc4 -z zip copy tmp.nc /vo...\n",
       "    Conventions:  CF-1.6\n",
       "    CDO:          Climate Data Operators version 1.9.6 (http://mpimet.mpg.de/...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (ensemble: 11, latitude: 450, longitude: 750, time: 31)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 2013-06-04 2013-06-05 ... 2013-07-04\n",
       "  * longitude  (longitude) float32 -24.95 -24.85 -24.75 ... 49.75 49.85 49.95\n",
       "  * latitude   (latitude) float32 74.95 74.85 74.75 74.65 ... 30.25 30.15 30.05\n",
       "  * ensemble   (ensemble) float64 0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0\n",
       "Data variables:\n",
       "    ups        (latitude, longitude) float32 ...\n",
       "    ldd        (latitude, longitude) float32 ...\n",
       "    rl2        (latitude, longitude) float32 ...\n",
       "    rl5        (latitude, longitude) float32 ...\n",
       "    rl20       (latitude, longitude) float32 ...\n",
       "    dis        (time, ensemble, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    CDI:          Climate Data Interface version 1.9.6 (http://mpimet.mpg.de/...\n",
       "    history:      Fri Feb 14 21:34:47 2020: cdo -f nc4 -z zip copy tmp.nc /vo...\n",
       "    Conventions:  CF-1.6\n",
       "    CDO:          Climate Data Operators version 1.9.6 (http://mpimet.mpg.de/..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = eps.rename({'lat': 'latitude'})\n",
    "eps = eps.rename({'lon': 'longitude'})\n",
    "\n",
    "eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:41:38.438929Z",
     "start_time": "2020-02-19T16:41:38.174209Z"
    }
   },
   "outputs": [],
   "source": [
    "elbe_basin_mask = get_basin_mask(eps.isel(time=0, ensemble=0)['dis'], 'Danube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbe_basin_mask2 = get_basin_mask(glofas['dis24'].isel(time=0), 'Danube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First converting LSTM predictions\n",
    "#Reshape to align in coordinates\n",
    "era5_masked = era5.interp(latitude=glofas.latitude, longitude=glofas.longitude).where(elbe_basin_mask2, drop=True)\n",
    "X = era5_masked\n",
    "\n",
    "\n",
    "#Downsampling our time from hourly to daily\n",
    "X = X.resample(time='1D').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_point = X.isel(latitude=57, longitude=134)\n",
    "y_point = glofas['dis24'].isel(latitude=57, longitude=134)\n",
    "\n",
    "X_point = X_point.drop(['latitude','longitude'])\n",
    "y_point = y_point.drop(['latitude','longitude'])\n",
    "\n",
    "Xda = X_point.to_array('features').T\n",
    "yda = y_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "regressor_model = open('../../models/Danube/danube_model.yaml', 'r').read()\n",
    "from keras.models import model_from_yaml\n",
    "loaded_regressor = model_from_yaml(regressor_model)\n",
    "loaded_regressor.load_weights('../../models/Danube/danube_model.h5')\n",
    "regressor = loaded_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_train = dict(time=slice(None, '2012'))\n",
    "period_test = dict(time=slice('2012', '2016'))\n",
    "\n",
    "\n",
    "X_train, y_train = Xda.loc[period_train], yda.loc[period_train]\n",
    "X_test, y_test = Xda.loc[period_test], yda.loc[period_test]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Applying feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "sc2 = MinMaxScaler(feature_range=(0,1))\n",
    "y_train_scaled = sc2.fit_transform(y_train.values.reshape(-1,1))\n",
    "\n",
    "X_test_scaled = sc.fit_transform(X_test)\n",
    "y_test_scaled = sc2.fit_transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.floodmodels import shift_input\n",
    "days_intake_length = 90\n",
    "X_test_final, y_test_final = shift_input(X_test_scaled, y_test_scaled, days_intake_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=sc2.inverse_transform(regressor.predict(X_test_final))\n",
    "y_pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sc2.inverse_transform(y_test_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_xr = xr.DataArray(y_pred_test.reshape(-1), dims=('time'), coords={'time': y_test.time.values[days_intake_length+1:]})\n",
    "y_pred_test_xr.plot(label = \"Predicted discharge\")\n",
    "\n",
    "#Plotting the real validation values\n",
    "#y_valid = np.concatenate(([y_orig.sel(time='2005-12-31').values], y_valid.values)).cumsum()\n",
    "#y_valid = np.delete(y_valid, 0)\n",
    "y_test_xr = xr.DataArray(y_test, dims=('time'), coords={'time': y_test.time.values})\n",
    "y_test_xr.plot(label=\"True discharge\")\n",
    "plt.title('LSTM model prediction trained on time values from 1981-2005')\n",
    "plt.legend(loc='upper left')\n",
    "# plt.savefig('./images/sampleanalysis/LSTM_ver3_multivariate_discharge_validationdata.png', dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:41:44.958758Z",
     "start_time": "2020-02-19T16:41:38.452294Z"
    }
   },
   "outputs": [],
   "source": [
    "eps_masked = eps.where(elbe_basin_mask, drop=True)\n",
    "eps_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:41:45.657607Z",
     "start_time": "2020-02-19T16:41:44.961784Z"
    }
   },
   "outputs": [],
   "source": [
    "eps_masked.isel(time=0, ensemble=2)['dis'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:41:45.738232Z",
     "start_time": "2020-02-19T16:41:45.662059Z"
    }
   },
   "outputs": [],
   "source": [
    "eps_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:41:46.079658Z",
     "start_time": "2020-02-19T16:41:45.742068Z"
    }
   },
   "outputs": [],
   "source": [
    "#instead of taking the mean you should take a specific point\n",
    "point_eps_masked = eps_masked.isel(latitude=57, longitude=134)['dis']\n",
    "point_eps_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T17:40:42.689521Z",
     "start_time": "2020-02-19T17:40:42.636683Z"
    }
   },
   "outputs": [],
   "source": [
    "glofas_point = glofas.loc[dict(time=slice('2013-05-23','2013-06-23'))].isel(latitude=57, longitude=134)\n",
    "\n",
    "glofas_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T17:40:44.504456Z",
     "start_time": "2020-02-19T17:40:43.539735Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "color_scheme = ['g', 'cyan', 'magenta', 'k']\n",
    "\n",
    "\n",
    "for ensemble_index in range(len(point_eps_masked.ensemble)):\n",
    "    point_eps_masked.loc[dict(time=slice('2013-05-23','2013-06-13'))].isel(ensemble=ensemble_index).plot(ax=ax, label=('Ensemble ' + str(ensemble_index)), lw=0.5, linestyle='--')\n",
    "    \n",
    "glofas_point['dis24'].plot(ax=ax, label=('True Discharge'), lw=4, linestyle='-', color='blue')\n",
    "y_pred_test_xr.loc[dict(time=slice('2013-05-23','2013-06-13'))].plot(ax=ax, label=(\"LSTM forecast\"), lw=2, linestyle='-')\n",
    "ax.set_ylabel('river discharge [m$^3$/s]')\n",
    "\n",
    "ax.legend(loc='upper left')                \n",
    "\n",
    "plt.title('Comparison of LSTM Model with GloFAS 30-Day Ensemble Forecasts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flood_prediction]",
   "language": "python",
   "name": "conda-env-flood_prediction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
